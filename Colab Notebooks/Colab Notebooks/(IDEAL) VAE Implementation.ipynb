{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57759,"status":"ok","timestamp":1643811324764,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"},"user_tz":0},"id":"e2fyx-x2yDbV","outputId":"a56ad9be-e31c-4a8a-80e7-799a732707b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Mounted at /content/drive\n"]}],"source":["from IPython import display\n","\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import PIL\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","import time\n","!pip install torch\n","import torch\n","\n","import h5py\n","from IPython.display import clear_output\n","\n","import math\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"markdown","source":["hey this is ideal\n"],"metadata":{"id":"bKWtvKTYpOT0"}},{"cell_type":"markdown","metadata":{"id":"jRpQ9jp-Y770"},"source":["#Load h5 data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":343,"status":"error","timestamp":1643811399374,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"},"user_tz":0},"id":"QyXo-DMiJBvR","outputId":"48513044-8d89-49ae-99d6-57db4936dcb9"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-65e24e384b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/data/neutrino_data/neutrino1.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Get an numpy array containing the event image, and reshape it from flat to 2x100x80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/MyDrive/data/neutrino_data/neutrino1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}],"source":["df = h5py.File(\"/content/drive/MyDrive/data/neutrino_data/neutrino1.h5\",'r')\n","\n","#Get an numpy array containing the event image, and reshape it from flat to 2x100x80\n","images = []\n","\n","print(np.shape(df['cvnmap']))\n","n = 0\n","for i in range(0,math.floor(len(df['cvnmap']))):\n","  event0=np.array(df['cvnmap'][i]).reshape((2,100,80))\n","  n+=1\n","  clear_output()\n","  print(str(100*round(n/math.floor(len(df['cvnmap'])),2)) + \"%\")\n","  images.append(event0[1].T)\n","\n","images = np.array(images)\n","print(images.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1643811325363,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"},"user_tz":0},"id":"Z9iNBX1oKm7_"},"outputs":[],"source":["train_images_unprocessed = np.array(images[:-math.floor(len(images)*0.2)])           #torch.tensor(np.array())\n","test_images_unprocessed  = np.array(images[len(images) - math.floor(len(images)*0.2):])\n","\n","print(train_images_unprocessed.shape)\n","print(test_images_unprocessed.shape)"]},{"cell_type":"markdown","metadata":{"id":"lrLsedx1J7G5"},"source":["#Load personal dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJ3c1o32Qh2f"},"outputs":[],"source":["def convertImagesToArray(imageptrs):\n","  images = []\n","\n","  n = 0\n","  for pImage in imageptrs:\n","    #print(plt.imread(pImage[:-1]))\n","    images.append(plt.imread(pImage[:-1]))\n","    n+=1\n","    clear_output()\n","    print(str(100 * round(n/len(imageptrs),2)) + \"%\")\n","\n","  return images"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":244443,"status":"ok","timestamp":1643062426303,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"},"user_tz":0},"id":"HpqWYxb8J6sg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57d3ae5f-2f8f-4712-c1f8-2e3af2b80640"},"outputs":[{"output_type":"stream","name":"stdout","text":["100.0%\n","torch.Size([1136, 128, 128, 3])\n","torch.Size([283, 128, 128, 3])\n"]}],"source":["file = open(\"/content/drive/MyDrive/Testing_VAE/pointerlists/stringlist.txt\", 'r')\n","\n","imageptrs = []\n","#print(len(file.readlines()))\n","for line in file.readlines():\n","  imageptrs.append(line)\n","\n","train_images_unprocessed = torch.tensor(np.array(convertImagesToArray(imageptrs[:-round(len(imageptrs)*0.2)])))\n","test_images_unprocessed  = torch.tensor(np.array(convertImagesToArray(imageptrs[-round(len(imageptrs)*0.2):-1])))\n","print(train_images_unprocessed.shape)\n","print(test_images_unprocessed.shape)"]},{"cell_type":"markdown","metadata":{"id":"i2e4FGC3J_um"},"source":["#Preprocessing functions"]},{"cell_type":"markdown","metadata":{"id":"v0Z5_BpHzGr1"},"source":["Define preprocessing procedure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XP8FiePKy7dh","executionInfo":{"status":"aborted","timestamp":1643811325364,"user_tz":0,"elapsed":18,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["def preprocess_images(imagelist):\n","  imagelist = imagelist.reshape((imagelist.shape[0], imagelist.shape[1], imagelist.shape[2], 3)) / torch.max(imagelist)\n","  #imagelist.reshape((imagelist.shape[0], imagelist.shape[1], imagelist.shape[2], 1))\n","  return tf.cast(imagelist, tf.float32) #np.where(imagelist > .5, 1.0, 0.0).astype('float32')\n","\n","def preprocess_images_reduce(imagelist):\n","  #print(imagelist.shape)\n","  imagelist_processed = []\n","  for i in range(len(imagelist)):\n","    img = imagelist[i]\n","    cropped_img = 255.*img[:,:80]/np.amax(img)\n","    imagelist_processed.append(cropped_img)\n","  imagelist_processed = np.array(imagelist_processed)\n","  #print(imagelist_processed.shape)\n","  imagelist_processed = torch.tensor(imagelist_processed)\n","  imagelist_processed = imagelist_processed.reshape((imagelist_processed.shape[0], imagelist_processed.shape[1], imagelist_processed.shape[2], 1))\n","  return tf.cast(imagelist_processed, tf.float32)\n","    "]},{"cell_type":"markdown","source":["#Preprocess using normalization of image brightness"],"metadata":{"id":"K-2gHOdp1YIE"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":194,"status":"error","timestamp":1643105184275,"user":{"displayName":"Ideal Buzoku","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00146322128793210446"},"user_tz":0},"id":"JRg5XjdcdH1I","colab":{"base_uri":"https://localhost:8080/","height":384},"outputId":"70eeb167-a3fa-4e85-ff67-71a464ad7ca3"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3987289574d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_unprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_images\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtest_images_unprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-7d412dda049f>\u001b[0m in \u001b[0;36mpreprocess_images\u001b[0;34m(imagelist)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mimagelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#imagelist.reshape((imagelist.shape[0], imagelist.shape[1], imagelist.shape[2], 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#np.where(imagelist > .5, 1.0, 0.0).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 44808000 into shape (5601,80,100,3)"]}],"source":["train_images = preprocess_images(train_images_unprocessed)\n","test_images  = preprocess_images( test_images_unprocessed)\n","\n","print(train_images.shape)\n","print(test_images.shape)"]},{"cell_type":"markdown","source":["#Preprocess NEUTRINO images to be square and normalized"],"metadata":{"id":"qbz1VZIj1q4W"}},{"cell_type":"code","source":["train_images = preprocess_images_reduce(train_images_unprocessed)\n","test_images  = preprocess_images_reduce( test_images_unprocessed)\n","\n","print(train_images.shape)\n","print(test_images.shape)"],"metadata":{"id":"zDMbt7SWcnii","executionInfo":{"status":"aborted","timestamp":1643811325365,"user_tz":0,"elapsed":18,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPpwnF8FzJkh"},"source":["Training/Testing Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8OM3q0AgzFuG","executionInfo":{"status":"aborted","timestamp":1643811325365,"user_tz":0,"elapsed":17,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["train_size = len(train_images)\n","batch_size = 256\n","test_size  = len(test_images) "]},{"cell_type":"markdown","metadata":{"id":"_JWvqRmgzQeh"},"source":["Batch/Dataset construction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIeVOWNIzNc1","executionInfo":{"status":"aborted","timestamp":1643811325366,"user_tz":0,"elapsed":17,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n","                 .shuffle(train_size).batch(batch_size))\n","test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n","                .shuffle(test_size).batch(batch_size))"]},{"cell_type":"markdown","metadata":{"id":"OJnokqabzqca"},"source":["#CVAE Network (Encoder + Decoder) for AURORA data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XLMRRVSzsB9"},"outputs":[],"source":["class CVAE(tf.keras.Model):\n","  \"\"\"Convolutional variational autoencoder.\"\"\"\n","\n","  def __init__(self, latent_dim):\n","    super(CVAE, self).__init__()\n","    self.latent_dim = latent_dim\n","    self.encoder = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.InputLayer(input_shape=(128, 128, 3)),\n","            tf.keras.layers.Reshape(target_shape=(128,128,3)),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=4, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=4, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=8, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=16, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.AvgPool2D(pool_size=(2,2)),\n","            tf.keras.layers.Conv2D(\n","                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.AvgPool2D(pool_size=(2,2)),\n","            tf.keras.layers.Conv2D(\n","                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Flatten(),\n","         \n","            # No activation\n","            tf.keras.layers.Dense(latent_dim + latent_dim),\n","        ]\n","    )\n","\n","    self.decoder = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n","            tf.keras.layers.Dense(units=4*4*batch_size, activation=tf.nn.relu),\n","            tf.keras.layers.Reshape(target_shape=(4,4,batch_size)),\n","\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=64, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=32, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=16, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=8, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","\n","            # No activation\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=3, kernel_size=3, strides=(2,2), padding='same')\n","        ]\n","    )\n","\n","  @tf.function\n","  def sample(self, eps=None):\n","    if eps is None:\n","      eps = tf.random.normal(shape=(100, self.latent_dim))\n","    return self.decode(eps, apply_sigmoid=True)\n","\n","  def encode(self, x):\n","    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n","    return mean, logvar\n","\n","  def reparameterize(self, mean, logvar):\n","    eps = tf.random.normal(shape=mean.shape)\n","    return eps * tf.exp(logvar * .5) + mean\n","\n","  def decode(self, z, apply_sigmoid=False):\n","    logits = self.decoder(z)\n","    if apply_sigmoid:\n","      probs = tf.sigmoid(logits)\n","      return probs\n","    return logits\n","\n","  def call(self, inputs):\n","    return self.decode(self.reparameterize(self.encode(inputs)))"]},{"cell_type":"markdown","source":["#CVAE for neutrino data"],"metadata":{"id":"hjJzy4Q6FqQf"}},{"cell_type":"code","source":["class CVAENeutrino(tf.keras.Model):\n","  \"\"\"Convolutional variational autoencoder.\"\"\"\n","\n","  def __init__(self, latent_dim):\n","    super(CVAENeutrino, self).__init__()\n","    self.latent_dim = latent_dim\n","    self.encoder = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.InputLayer(input_shape=(80, 80, 1)),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=4, kernel_size=3, strides=(4,4), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=4, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=4, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=8, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=16, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.AvgPool2D(pool_size=(2,2)),\n","            tf.keras.layers.Conv2D(\n","                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.AvgPool2D(pool_size=(2,2)),\n","            tf.keras.layers.Conv2D(\n","                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Flatten(),\n","         \n","            # No activation\n","            tf.keras.layers.Dense(latent_dim + latent_dim),\n","        ]\n","    )\n","\n","    self.decoder = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n","            tf.keras.layers.Dense(units=5*5*batch_size, activation=tf.nn.relu),\n","            tf.keras.layers.Reshape(target_shape=(5,5,batch_size)),\n","\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=64, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=32, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=16, kernel_size=3, strides=(2,2), padding='same',\n","                activation='relu'),\n","\n","            # No activation\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=1, kernel_size=3, strides=(2,2), padding='same')\n","        ]\n","    )\n","\n","  @tf.function\n","  def sample(self, eps=None):\n","    if eps is None:\n","      eps = tf.random.normal(shape=(100, self.latent_dim))\n","    return self.decode(eps, apply_sigmoid=True)\n","\n","  def encode(self, x):\n","    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n","    return mean, logvar\n","\n","  def reparameterize(self, mean, logvar):\n","    eps = tf.random.normal(shape=mean.shape)\n","    return eps * tf.exp(logvar * .5) + mean\n","\n","  def decode(self, z, apply_sigmoid=False):\n","    logits = self.decoder(z)\n","    if apply_sigmoid:\n","      probs = tf.sigmoid(logits)\n","      return probs\n","    return logits\n","\n","  def call(input):\n","    return self.decode(self.encode(input))"],"metadata":{"id":"TPHEd5VkFp-s","executionInfo":{"status":"aborted","timestamp":1643811325366,"user_tz":0,"elapsed":16,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sLNcgZnWz5aE"},"source":["#Loss function + training step methods"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43DnDySdz8bM","executionInfo":{"status":"aborted","timestamp":1643811325367,"user_tz":0,"elapsed":17,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(1e-3)\n","\n","\n","def log_normal_pdf(sample, mean, logvar, raxis=1):\n","  log2pi = tf.math.log(2. * np.pi)\n","  return tf.reduce_sum(\n","      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n","      axis=raxis)\n","\n","\n","def compute_loss(model, x):\n","  mean, logvar = model.encode(x)\n","  z = model.reparameterize(mean, logvar)\n","  x_logit = model.decode(z)\n","  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n","  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n","  logpz = log_normal_pdf(z, 0., 0.)\n","  logqz_x = log_normal_pdf(z, mean, logvar)\n","  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n","\n","\n","@tf.function\n","def train_step(model, x, optimizer):\n","  \"\"\"Executes one training step and returns the loss.\n","\n","  This function computes the loss and gradients, and uses the latter to\n","  update the model's parameters.\n","  \"\"\"\n","  with tf.GradientTape() as tape:\n","    loss = compute_loss(model, x)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"]},{"cell_type":"markdown","metadata":{"id":"28SZTkw90Lw4"},"source":["#Setup for training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1643811325367,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"},"user_tz":0},"id":"GtFQx64z0MMs"},"outputs":[],"source":["train_size = len(train_images)\n","batch_size = 128\n","test_size  = len(test_images)\n","train_dataset = (tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n","test_dataset  = (tf.data.Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))\n","\n","epochs = 1000\n","# set the dimensionality of the latent space to a plane for visualization later\n","latent_dim = 25\n","num_examples_to_generate = 16\n","\n","# keeping the random vector constant for generation (prediction) so\n","# it will be easier to see the improvement.\n","random_vector_for_generation = tf.random.normal(\n","    shape=[num_examples_to_generate, latent_dim])\n","model = CVAENeutrino(latent_dim)"]},{"cell_type":"markdown","metadata":{"id":"iY57Axuu0SRB"},"source":["#Taking a sample and epoch, make and show the images the model predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hct6d7TM0R_f","executionInfo":{"status":"aborted","timestamp":1643811325368,"user_tz":0,"elapsed":17,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["def generate_and_save_images(model, epoch, test_sample):\n","  mean, logvar = model.encode(test_sample)\n","  z = model.reparameterize(mean, logvar)\n","  predictions = model.sample(z)\n","\n","  fig1 = plt.figure(figsize=(4, 4))\n","  for i in range(predictions.shape[0]):\n","    plt.subplot(4, 4, i + 1)\n","    plt.imshow(test_sample[i, :, :, 0])\n","    plt.axis('off')\n","\n","  fig2 = plt.figure(figsize=(4, 4))\n","  for i in range(predictions.shape[0]):\n","    plt.subplot(4, 4, i+1)\n","    plt.imshow(predictions[i, :, :, 0])#, cmap='gray') \n","    plt.axis('off')\n","\n","  # tight_layout minimizes the overlap between 2 sub-plots\n","  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"xv_7QCPj0h87"},"source":["#Pick a sample of the test set for generating output images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FWPfzFE0iP9","executionInfo":{"status":"aborted","timestamp":1643811325368,"user_tz":0,"elapsed":16,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["# Pick a sample of the test set for generating output images\n","assert batch_size >= num_examples_to_generate\n","for test_batch in test_dataset.take(1):\n","  test_sample = test_batch[0:num_examples_to_generate, :, :]"]},{"cell_type":"markdown","metadata":{"id":"ZiBk0NGJ0l0H"},"source":["#Using a sample, make a set of prediction images"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"Km1PRaRI0lYh","outputId":"ea7101f7-def2-4ad7-9f6f-434c130cc9e5","executionInfo":{"status":"error","timestamp":1643811329643,"user_tz":0,"elapsed":4,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e68b9f8d85ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_and_save_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'generate_and_save_images' is not defined"]}],"source":["generate_and_save_images(model, 0, test_sample)\n","\n","for epoch in range(1, epochs + 1):\n","  start_time = time.time()\n","  for train_x in train_dataset:\n","    train_step(model, train_x, optimizer)\n","  end_time = time.time()\n","\n","  loss = tf.keras.metrics.Mean()\n","  for test_x in test_dataset:\n","    loss(compute_loss(model, test_x))\n","  elbo = -loss.result()\n","  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n","        .format(epoch, elbo, end_time - start_time))\n","  if epoch%30 == 0:\n","    display.clear_output(wait=False)\n","    generate_and_save_images(model, epoch, test_sample)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e57YIcXo0_7S","executionInfo":{"status":"aborted","timestamp":1643811329642,"user_tz":0,"elapsed":2,"user":{"displayName":"DPUCLAurora UCLMSc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKJ94RHpSutuLCqbQ5fbxcPuRZhFdhXVtrL1EB=s64","userId":"17329592729593916410"}}},"outputs":[],"source":["anim_file = 'cvae.gif'\n","\n","with imageio.get_writer(anim_file, mode='I') as writer:\n","  filenames = glob.glob('image*.png')\n","  filenames = sorted(filenames)\n","  n = 0\n","  for filename in filenames:\n","    if n%1==0:\n","      image = imageio.imread(filename)\n","      writer.append_data(image)\n","    n = n + 1\n","  image = imageio.imread(filename)\n","  writer.append_data(image)"]},{"cell_type":"markdown","source":["#Saving the model"],"metadata":{"id":"yeWkEpWXzZhR"}},{"cell_type":"code","source":["model_name = \"modelTEST\"\n","model.save_weights(\"/content/drive/MyDrive/Testing_VAE/model_checkpoints/\"+model_name)"],"metadata":{"id":"Iw-tnbrlzZLf"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["jRpQ9jp-Y770","lrLsedx1J7G5","K-2gHOdp1YIE","qbz1VZIj1q4W","hjJzy4Q6FqQf"],"name":"(IDEAL) VAE Implementation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}